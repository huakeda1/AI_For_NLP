{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-02, Probability Model A First Look: An Introduction of Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "1. Review the course online programming code; \n",
    "2. Review the main questions; \n",
    "3. Using wikipedia corpus to build a language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review the course online programming code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this part, you should re-code the programming task in our online course.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review the main points of this lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. How to Github and Why do we use Jupyter and Pycharm; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:     \n",
    "(1) github 常用操作 create repository/clone/init/add/commit/pull/push;  \n",
    "(2) Jupyter支持markdown和python code模式方便学习时记录笔记和代码，同时梳理总结思路;   \n",
    "(3) Pycharm是python工程中常用的IDE，支持调试、运行和git等常用操作，对于大型的项目来说比Jupyter更加方便；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 概率模型用已有样本的概率来预测未知样本发生的可能性，概率模型需要考虑事件的独立性和相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "(1) 天气结果预测 [Ref link：Probability_of_precipitation](https://en.wikipedia.org/wiki/Probability_of_precipitation);  \n",
    "(2) Google 搜索结果排序[Ref link：PageRank](https://en.wikipedia.org/wiki/PageRank);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "(1) 概率模型简单且在很多情况下有效；  \n",
    "(2) 基于模式匹配的方法需要人工制定规则，较为复杂，并且规则较少时会对模型有较大的影响；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 语言模型是通过对语料建模，方便处理文本相关的任务，如文本预测、主题识别等；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  6. Can you came up with some sceneraies at which we could use Language Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 拼音输入法中的联想词，google搜索，微信语音转文字，智能客服等；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 1-gram 语言模型假设语句中的单词都是相互独立的，给定语料库模型能够计算出每个单词出现的概率，一个句子的概率就等于每个单词在语料库中出现的概率乘积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- disadvantages：没有考虑单词的上下文，结果和真实世界中的结果存在较大的误差；\n",
    "- advantages：模型简单，能够处理较大的语料库；适用于预测单词的场景；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.  What't the 2-gram models; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  2-gram假设单词仅仅与前一个单词有关，给定语料库可以计算这两个单词的联合概率和单个单词的概率，一个句子的概率就等于给定前一个单词时出现当前单词的条件概率的乘积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. what's the web crawler, and can you implement a simple crawler? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 网页爬虫通过模拟网络请求获取网页资源，对网页资源进行正字匹配处理，获取目标资源。 \n",
    "\n",
    "根据课程内容实现了简单的网易云音乐热门评论的爬虫，see file: [MusicHotCommentWebCrawler.ipynb](MusicHotCommentWebCrawler.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.  There may be some issues to make our crwaler programming difficult, what are these, and how do we solve them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "（1）反扒策略应对，可以使用IP代理等方案；  \n",
    "（2）数据解析，需要根据网站的返回数据格式做定制化的程序；   \n",
    "（3）请求中可能有加密参数，可以发起真实的请求获取参数或者破解加密算法；  \n",
    "（4）数据量较大时爬取速度较慢，单机可以使用多线程的方案；  \n",
    "（5）网站参数可能会随着时间的改变而改变，需要根据最新版本修改代码；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. What't the Regular Expression and how to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 正则表达式是由字母、数字和特殊符号组成的一个字符串；正则表达式可以用来匹配、过滤文本；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Wikipedia dataset to finish the language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: You need to download the corpus from wikipedis:\n",
    "> https://dumps.wikimedia.org/zhwiki/20190401/\n",
    "\n",
    "Step 2: You may need the help of wiki-extractor:\n",
    "\n",
    "> https://github.com/attardi/wikiextractor  \n",
    "> https://pypi.org/project/wiki-dump-parser/\n",
    "\n",
    "Step 3: Using the technologies and methods to finish the language model; \n",
    "> see below\n",
    "\n",
    "Step 4: Try some interested sentence pairs, and check if your model could fit them\n",
    "\n",
    "> see below\n",
    "\n",
    "Step 5: If we need to solve following problems, how can language model help us? \n",
    "\n",
    "+ Voice Recognization.\n",
    "+ Sogou *pinyin* input.\n",
    "+ Auto correction in search engine. \n",
    "+ Abnormal Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans: Step3 Language Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Preprocess data**\n",
    "+ 下载 wiki dump, 文件大小约 1.7G;\n",
    "+ 下载 wiki extractor 解析dump文件，并以json格式存储：   \n",
    "`python ./wikiextractor-master/WikiExtractor.py -b 500M -o zhwiki-20190420 zhwiki-20190420-pages-articles.xml.bz2 --json`\n",
    "\n",
    "+ json文件样例如下，做语言模型时只需要提取**text**字段内容即可；  \n",
    "\n",
    "```\n",
    "{\"url\": \"https://zh.wikipedia.org/wiki?curid=87\", \"text\": \"海洋学\\n\\n海洋学（）是研究海洋的自然现象、性质及其变化规律，以及开发利用海洋的知识体系。它是研究海洋的地理学的分支。它涵盖了广泛的主题，包括生态系统动力学、洋流、波浪和; 板块构造和海底地质; 以及各种化学物质和物理性质在海洋内及其边界的通量。这些不同的主题反映了海洋学家融合多个学科对世界洋的进一步认识和对天文学，生物学，化学，气候学，地理学，地质学，水文科学，气象学和物理学中的过程的理解。研究了地质历史中海洋的历史。\\n\\n人類在史前時代就有了關於海浪和洋流的知識。科學形式海洋研究的雛型可以追溯到古希臘，亞里士多德和斯特拉波記錄下了對潮汐的觀測。但早期海洋探索主要目的在於製圖，儘管也用了鉛線做深度探測，人類對海洋的了解相當長時間都局限在淺層區域。19世紀中葉，英國皇家海軍嘗試繪製全世界的海岸線，發現大部分海洋似乎都相當深。\\n開啟現代科學海洋學的是1872-76年的挑戰者號遠征。英國政府1871年接受皇家學會的建議，宣布探索世界大洋並進行科學調查。由威維爾·湯姆森和發起，改裝了皇家海軍的挑戰者號並配備獨立的自然史和化學實驗室。在湯姆森的科學監督下，近7萬海里（13萬公里）的航程總共進行了492次深海探通、133條海底挖掘、151次開闊水域拖網和263次連續水溫觀測，並發現約4700種新的海洋生物。挑戰者號遠征是人類史上第一次真正海洋巡航的科學考察，為整個學術和研究學科奠定了基礎。約翰·默里之後在愛丁堡大學繼續研究，這裡在20世紀仍然是海洋研究的中心。 默里是第一個研究海洋峽谷的人，特別是大西洋中洋脊，並繪製了海洋中的沉積物。 他試圖根據鹽度和溫度的觀測繪製出世界洋流，並首先正確地了解珊瑚礁發展的性質。\\n\\n十九世紀末，其他西方國家陸續派出科學考察隊。第一艘海洋調查船，美國的建於1882年。1893年，挪威科學家弗里喬夫·南森讓他的調查船前进号凍結在北極的海冰上三年，長時間在固定地點獲得海洋學、氣象和天文數據。由約翰·默里和所領導1910年為期四個月的北大西洋考察團，是迄今最雄心勃勃的海洋學和海洋動物學計畫。第一次聲學測量海深在1914年。1925年至1927年間，“流星”考察隊使用回聲測深儀收集了70,000次海洋深度測量，探勘大西洋中洋脊 。\\n50年代，瑞士物理學家奧居斯特·皮卡爾發明，並利用來研究海洋的深度。1953年，和發現了沿著大西洋中洋脊延伸的全球洋脊系統; 1954年，蘇聯的北極研究所發現了北冰洋的海底山脈。 1960年哈里·哈蒙德·赫斯發展了海底擴張學說。1958年美國核潛艇鸚鵡螺號第一次在北極進行了冰封航程，並抵達北極點。1962年，聖地牙哥加利福尼亞大學建立了能夠在所有海洋中運作，長108公尺的浮式儀器平台（FLIP）。\\n\\n70年代開始，大型電腦開始應用於海洋學，對海洋條件進行數值計算，視其為整體環境變化預測的一部分。同時也廣泛地設置海洋浮標，以取得更完整的觀測資料。另外，大洋鑽探計劃始於1966年。海底熱泉則在1977年由約翰·科里斯和羅伯·巴拉德搭乘發現。\\n\\n近年來海洋學的研究特別著重在海洋酸化、海洋熱含量、洋流、聖嬰現象、甲烷水合物蘊藏、碳循環、沿海侵蝕、風化和氣候變化中氣候回饋的交互作用。研究海洋與了解全球氣候變遷、潛在的全球暖化和相關生物圈問題有關。由於蒸發、降水以及熱通量（和太陽日照），大氣和海洋是緊密聯繫的。風壓是驅動洋流的主要動力，海洋是大氣二氧化碳的吸收庫。所有這些因素都與海洋的生物地球化學有關。\\n\\n海洋學研究分為四大部分：\\n\\n\\n\", \"id\": \"87\", \"title\": \"海洋学\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3396464\r\n",
      "-rw-r--r--  1 liling  staff       35747 Aug 19 21:57 Assignment-02.ipynb\r\n",
      "-rw-r--r--  1 liling  staff      143410 Aug 16 22:21 Lesson-02-LanguageModel.ipynb\r\n",
      "-rw-r--r--  1 liling  staff      175172 Apr 15 23:42 MusicHotCommentWebCrawler.ipynb\r\n",
      "drwxr-xr-x  5 liling  staff         160 Aug 19 08:18 \u001b[1m\u001b[36mdatasource\u001b[m\u001b[m/\r\n",
      "-rw-r--r--  1 liling  staff      128562 Apr 15 23:39 hot_comment.csv\r\n",
      "-rwxr-xr-x  1 liling  staff        3883 Aug 19 09:24 \u001b[31mprocess_wikipedia.py\u001b[m\u001b[m*\r\n",
      "drwxr-xr-x@ 9 liling  staff         288 Aug 19 08:23 \u001b[1m\u001b[36mwikiextractor-master\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  4 liling  staff         128 Aug 19 21:18 \u001b[1m\u001b[36mzhwiki-20190420\u001b[m\u001b[m/\r\n",
      "-rw-r--r--@ 1 liling  staff  1738486393 Aug 17 15:57 zhwiki-20190420-pages-articles.xml.bz2\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将json转成csv文件存储\n",
    "import glob\n",
    "import json, csv\n",
    "import datetime\n",
    "      \n",
    "output = 'zhwiki-20190420-pages-articles.csv'\n",
    "headers = True\n",
    "with open(output, 'w') as csvf:\n",
    "    for filename in glob.iglob('zhwiki-20190420/*/*'):\n",
    "        with open(filename, encoding='utf-8') as jsonf:\n",
    "            for line in jsonf:\n",
    "                data = json.loads(line)\n",
    "                if headers:\n",
    "                    keys = []\n",
    "                    for k, v in data.items():\n",
    "                        keys.append(k)\n",
    "                    writer = csv.DictWriter(csvf, fieldnames=keys)\n",
    "                    writer.writeheader()\n",
    "                    headers = False\n",
    "                writer.writerow(data)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zhwiki-20190420-pages-articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461182</td>\n",
       "      <td>乍得争取团结和社会主义行动\\n\\n乍得争取团结和社会主义行动（法语：Action Tchad...</td>\n",
       "      <td>4461182</td>\n",
       "      <td>乍得争取团结和社会主义行动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461193</td>\n",
       "      <td>国际法与国内法的关系\\n\\n国际法与国内法可能产生冲突，当两者冲突时的处理方法就体现了国际法...</td>\n",
       "      <td>4461193</td>\n",
       "      <td>国际法与国内法的关系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461205</td>\n",
       "      <td>星星舰队\\n\\n《星星舰队》（Xボンバー、エックスボンバー）是永井豪原作的电视特攝人偶劇。\\...</td>\n",
       "      <td>4461205</td>\n",
       "      <td>星星舰队</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461211</td>\n",
       "      <td>苏丹共产党\\n\\n苏丹共产党（，罗马化：Al-Hizb al-Shuyui al-Sudan...</td>\n",
       "      <td>4461211</td>\n",
       "      <td>苏丹共产党</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461213</td>\n",
       "      <td>宝贝，对不起\\n\\n《宝贝，对不起》（）中国大陆励志电影，导演潘礼平、杜林、刘可、李锐、王骏...</td>\n",
       "      <td>4461213</td>\n",
       "      <td>宝贝，对不起</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461214</td>\n",
       "      <td>一院站\\n\\n一院站（朝鲜语：일원역；）曾为朝鲜铁路博川线上的一个车站，位于平安北道博川郡，...</td>\n",
       "      <td>4461214</td>\n",
       "      <td>一院站</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461215</td>\n",
       "      <td>肯尼亚共产党\\n\\n肯尼亚共产党（，缩写为CPK）是肯尼亚的一个共产主义政党。该党成立于19...</td>\n",
       "      <td>4461215</td>\n",
       "      <td>肯尼亚共产党</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461222</td>\n",
       "      <td>安哥拉共产主义共同体党\\n\\n安哥拉共产主义共同体党（葡萄牙语：Partido da Com...</td>\n",
       "      <td>4461222</td>\n",
       "      <td>安哥拉共产主义共同体党</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461233</td>\n",
       "      <td>索南札巴\\n\\n索南札巴（；），《明史》上作锁南札思巴噫监藏，西藏歷史上帕木竹巴的第四代第悉...</td>\n",
       "      <td>4461233</td>\n",
       "      <td>索南札巴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://zh.wikipedia.org/wiki?curid=4461243</td>\n",
       "      <td>爱我就陪我看电影\\n\\n《爱我就陪我看电影》（）中国大陆爱情喜剧片，导演牛朝阳，主演吴镇宇、...</td>\n",
       "      <td>4461243</td>\n",
       "      <td>爱我就陪我看电影</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           url  \\\n",
       "0  https://zh.wikipedia.org/wiki?curid=4461182   \n",
       "1  https://zh.wikipedia.org/wiki?curid=4461193   \n",
       "2  https://zh.wikipedia.org/wiki?curid=4461205   \n",
       "3  https://zh.wikipedia.org/wiki?curid=4461211   \n",
       "4  https://zh.wikipedia.org/wiki?curid=4461213   \n",
       "5  https://zh.wikipedia.org/wiki?curid=4461214   \n",
       "6  https://zh.wikipedia.org/wiki?curid=4461215   \n",
       "7  https://zh.wikipedia.org/wiki?curid=4461222   \n",
       "8  https://zh.wikipedia.org/wiki?curid=4461233   \n",
       "9  https://zh.wikipedia.org/wiki?curid=4461243   \n",
       "\n",
       "                                                text       id          title  \n",
       "0  乍得争取团结和社会主义行动\\n\\n乍得争取团结和社会主义行动（法语：Action Tchad...  4461182  乍得争取团结和社会主义行动  \n",
       "1  国际法与国内法的关系\\n\\n国际法与国内法可能产生冲突，当两者冲突时的处理方法就体现了国际法...  4461193     国际法与国内法的关系  \n",
       "2  星星舰队\\n\\n《星星舰队》（Xボンバー、エックスボンバー）是永井豪原作的电视特攝人偶劇。\\...  4461205           星星舰队  \n",
       "3  苏丹共产党\\n\\n苏丹共产党（，罗马化：Al-Hizb al-Shuyui al-Sudan...  4461211          苏丹共产党  \n",
       "4  宝贝，对不起\\n\\n《宝贝，对不起》（）中国大陆励志电影，导演潘礼平、杜林、刘可、李锐、王骏...  4461213         宝贝，对不起  \n",
       "5  一院站\\n\\n一院站（朝鲜语：일원역；）曾为朝鲜铁路博川线上的一个车站，位于平安北道博川郡，...  4461214            一院站  \n",
       "6  肯尼亚共产党\\n\\n肯尼亚共产党（，缩写为CPK）是肯尼亚的一个共产主义政党。该党成立于19...  4461215         肯尼亚共产党  \n",
       "7  安哥拉共产主义共同体党\\n\\n安哥拉共产主义共同体党（葡萄牙语：Partido da Com...  4461222    安哥拉共产主义共同体党  \n",
       "8  索南札巴\\n\\n索南札巴（；），《明史》上作锁南札思巴噫监藏，西藏歷史上帕木竹巴的第四代第悉...  4461233           索南札巴  \n",
       "9  爱我就陪我看电影\\n\\n《爱我就陪我看电影》（）中国大陆爱情喜剧片，导演牛朝阳，主演吴镇宇、...  4461243       爱我就陪我看电影  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4218428"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑笔记本性能，随机读取10%的数据\n",
    "ALL_TEXT = df.sample(frac=0.1)['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105461"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ALL_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 去除非中文字符**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return ''.join(re.findall(u'[\\u4e00-\\u9fa5\\d+]+', string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'星星舰队星星舰队'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token('星星舰队\\n\\n《星星舰队》（Xボンバー、エックスボンバー）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'苏丹共产党苏丹共产党罗马化'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token('苏丹共产党\\n\\n苏丹共产党（，罗马化：Al-Hizb al-Shuyui al-Sudan...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CLEAN_TOKEN = [token(text) for text in ALL_TEXT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = ''.join(token for token in ALL_CLEAN_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36890098"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 切词，统计词频**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['安哥拉', '共产主义', '共同体', '党']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut('安哥拉共产主义共同体党')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['国际法', '与', '国内法', '可能', '产生', '冲突']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut('国际法与国内法可能产生冲突')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TOKENS = cut(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 1007362),\n",
       " ('年', 297174),\n",
       " ('在', 287307),\n",
       " ('是', 222260),\n",
       " ('和', 152147),\n",
       " ('了', 136187),\n",
       " ('月', 135567),\n",
       " ('於', 130125),\n",
       " ('為', 95033),\n",
       " ('有', 86259)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计词频\n",
    "from collections import Counter\n",
    "\n",
    "words_count = Counter(ALL_TOKENS)\n",
    "words_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequences_all = [f for w, f  in words_count.most_common()]\n",
    "frequences_sum = sum(frequences_all)\n",
    "\n",
    "def get_prob(word):\n",
    "    esp = 1 / frequences_sum\n",
    "    if word in words_count:\n",
    "        return words_count[word] / frequences_sum\n",
    "    return esp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) 2-Gram Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2_grams_words = [''.join(ALL_TOKENS[i:i+2]) for i in range(len(ALL_TOKENS[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2_gram_sum = len(all_2_grams_words)\n",
    "all_2_gram_counter = Counter(all_2_grams_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_prob(w1, w2):\n",
    "    if w1 + w2 in all_2_gram_counter:\n",
    "        return all_2_gram_counter[w1+w2] / all_2_gram_sum\n",
    "    else:\n",
    "        return 1 / all_2_gram_sum\n",
    "    \n",
    "\n",
    "def get_prob_2_gram(previous, word):\n",
    "    return get_combination_prob(previous, word) / get_prob(previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def language_model_2_gram(string):\n",
    "    token_list = cut(string)\n",
    "    probability = 1\n",
    "    \n",
    "    for i, word in enumerate(token_list):\n",
    "        if i == 0:\n",
    "            probability = get_prob(word)\n",
    "        else:\n",
    "            probability = probability * get_prob_2_gram(token_list[i-1], word)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.63949505320178e-15"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('新一轮流感病毒正在东京蔓延')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7208664548140867e-06"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('中华人民共和国成立了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.263943384118637e-12"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('中国的图灵奖获得者')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.578957752344439e-13"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('东汉末年分三国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.889900580245652e-18"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram(\"小明今天抽奖抽到一台波音飞机\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.934805637449065e-18"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram(\"小明今天抽奖抽到一台苹果手机\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### **Step4 Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迪迦奥特曼在东八区大战赛亚人 is more possible\n",
      "----迪迦奥特曼在东八区大战赛亚人 with probility 7.0844014113289e-18\n",
      "----迪迦奥特在城市里大战不知名的怪兽 with probility 1.1357068065873391e-29\n",
      "维多利亚是贝克汉姆的老婆 is more possible\n",
      "----维多利亚是一只漂亮的苏格兰折耳猫 with probility 7.238329373839808e-22\n",
      "----维多利亚是贝克汉姆的老婆 with probility 6.666666574677283e-19\n",
      "诸葛亮是著名的军事家 is more possible\n",
      "----诸葛亮是著名的军事家 with probility 1.4288189322529868e-16\n",
      "----诸葛亮是一个远程消耗型的法师 with probility 1.7476760283661422e-21\n",
      "君不见黄河之水天上来，奔流到海不复回 is more possible\n",
      "----君不见黄河之水天上来，奔流到海不复回 with probility 7.007221451200093e-24\n",
      "----你看不到黃河水来自哪里，一直涌向大海的不会回來 with probility 1.3616208753877092e-34\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"迪迦奥特曼在东八区大战赛亚人  迪迦奥特在城市里大战不知名的怪兽\",\n",
    "    \"维多利亚是一只漂亮的苏格兰折耳猫 维多利亚是贝克汉姆的老婆\",\n",
    "    \"诸葛亮是著名的军事家 诸葛亮是一个远程消耗型的法师\",\n",
    "    \"君不见黄河之水天上来，奔流到海不复回  你看不到黃河水来自哪里，一直涌向大海的不会回來\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = language_model_2_gram(s1), language_model_2_gram(s2)\n",
    "    better =  s1 if p1 > p2 else s2\n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + '{} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + '{} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 4. Compared to the previous learned parsing and pattern match problems. What's the advantage and disavantage of Probability Based Methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "**advantages:**  \n",
    "- 能够处理大量的数据；\n",
    "- 模型简单方便，易于理解；\n",
    "\n",
    "**disadvantages:**\n",
    "- 结果依赖于语料，通用性不强；\n",
    "- 实际情况中需要考虑周围多个词的条件概率，可能会使模型更加复杂；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optional)  How to solve *OOV* problem?\n",
    "\n",
    "If some words are not in our dictionary or corpus. When we using language model, we need to overcome this `out-of-vocabulary`(OOV) problems. There are so many intelligent man to solve this probelm. \n",
    "\n",
    "-- \n",
    "\n",
    "The first question is: \n",
    "\n",
    "**Q1: How did you solve this problem in your programming task?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 词不存在时假设其只出现了一次；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the sencond question is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: Read about the 'Turing-Good Estimator', can explain the main points about this method, and may implement this method in your programming task**\n",
    "\n",
    "Reference: \n",
    "+ https://www.wikiwand.com/en/Good%E2%80%93Turing_frequency_estimation\n",
    "+ https://github.com/Computing-Intelligence/References/blob/master/NLP/Natural-Language-Processing.pdf, Page-37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 古德·图灵估计是一种平滑技术，其核心思想是：对于没有看见的事件不能假设其发生的概率就是0，而是需要从概率估计总量中抽取一小部分赋予这些没有看见的事件。计算公式由   $ N = \\sum rN_r $ 改为    $d_r = (r+1)\\frac{N_{r+1}}{N_r}$, $N = \\sum d_r N_r$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
