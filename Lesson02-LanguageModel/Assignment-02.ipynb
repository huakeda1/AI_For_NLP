{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-02, Probability Model A First Look: An Introduction of Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "1. Review the course online programming code; \n",
    "2. Review the main questions; \n",
    "3. Using wikipedia corpus to build a language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review the course online programming code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this part, you should re-code the programming task in our online course.*\n",
    "\n",
    "[See: Lesson-02-LanguageModel-and-Machine-Learning.ipynb](Lesson-02-LanguageModel-and-Machine-Learning.ipynb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review the main points of this lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. How to Github and Why do we use Jupyter and Pycharm; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:     \n",
    "(1) github 常用操作 create repository/clone/init/add/commit/pull/push;  \n",
    "(2) Jupyter支持markdown和python code模式方便学习时记录笔记和代码，同时梳理总结思路;   \n",
    "(3) Pycharm是python工程中常用的IDE，支持调试、运行和git等常用操作，对于大型的项目来说比Jupyter更加方便；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 概率模型用已有样本的概率来预测未知样本发生的可能性，概率模型需要考虑事件的独立性和相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "(1) 天气结果预测 [Ref link：Probability_of_precipitation](https://en.wikipedia.org/wiki/Probability_of_precipitation);  \n",
    "(2) Google 搜索结果排序[Ref link：PageRank](https://en.wikipedia.org/wiki/PageRank);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "(1) 概率模型简单且在很多情况下有效；  \n",
    "(2) 基于模式匹配的方法需要人工制定规则，较为复杂，并且规则较少时会对模型有较大的影响；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 语言模型是通过对语料建模，方便处理文本相关的任务，如文本预测、主题识别等；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  6. Can you came up with some sceneraies at which we could use Language Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 拼音输入法中的联想词，google搜索，微信语音转文字，智能音响等；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 1-gram 语言模型假设语句中的单词都是相互独立的，给定语料库模型能够计算出每个单词出现的概率，一个句子的概率就等于每个单词在语料库中出现的概率乘积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- disadvantages：没有考虑单词的上下文，结果和真实世界中的结果存在较大的误差；\n",
    "- advantages：模型简单，能够处理较大的语料库；适用于预测单词的场景；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.  What't the 2-gram models; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  2-gram假设单词仅仅与前一个单词有关，给定语料库可以计算这两个单词的联合概率和单个单词的概率，一个句子的概率就等于给定前一个单词时出现当前单词的条件概率的乘积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. what's the web crawler, and can you implement a simple crawler? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 网页爬虫通过模拟网络请求获取网页资源，对网页资源进行正字匹配处理，获取目标资源。 \n",
    "\n",
    "根据课程内容实现了简单的网易云音乐热门评论的爬虫，see file: [MusicHotCommentWebCrawler.ipynb](MusicHotCommentWebCrawler.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.  There may be some issues to make our crwaler programming difficult, what are these, and how do we solve them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "（1）反扒策略应对，可以使用IP代理等方案；  \n",
    "（2）数据解析，需要根据网站的返回数据格式做定制化的程序；   \n",
    "（3）请求中可能有加密参数，可以发起真实的请求获取参数或者破解加密算法；  \n",
    "（4）数据量较大时爬取速度较慢，单机可以使用多线程的方案；  \n",
    "（5）网站参数可能会随着时间的改变而改变，需要根据最新版本修改代码；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. What't the Regular Expression and how to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 正则表达式是由字母、数字和特殊符号组成的一个字符串；正则表达式可以用来匹配、过滤文本；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Wikipedia dataset to finish the language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: You need to download the corpus from wikipedis:\n",
    "> https://dumps.wikimedia.org/zhwiki/20190401/\n",
    "\n",
    "Step 2: You may need the help of wiki-extractor:\n",
    "\n",
    "> https://github.com/attardi/wikiextractor\n",
    "\n",
    "Step 3: Using the technologies and methods to finish the language model; \n",
    "> see below\n",
    "\n",
    "Step 4: Try some interested sentence pairs, and check if your model could fit them\n",
    "\n",
    "> see below\n",
    "\n",
    "Step 5: If we need to solve following problems, how can language model help us? \n",
    "\n",
    "+ Voice Recognization.\n",
    "+ Sogou *pinyin* input.\n",
    "+ Auto correction in search engine. \n",
    "+ Abnormal Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans: Step3 Language Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki_dump_parser as parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "The following line has imcomplete info and therefore it's been removed from the dataset:\n",
      "['3340118', '|忍者蛇蛇丸君：櫻花公主與火龍的祕密|', '0', '24972867', '2013-02-12T12:35:48Z', '', '', '-1']\n",
      "The following line has imcomplete info and therefore it's been removed from the dataset:\n",
      "['3340119', '|忍者蛇蛇丸君 櫻花公主與火龍的秘密|', '0', '24972881', '2013-02-12T12:36:52Z', '', '', '-1']\n",
      "The following line has imcomplete info and therefore it's been removed from the dataset:\n",
      "['3340121', '|忍者蛇蛇丸君：櫻花公主與火龍的秘密|', '0', '24972886', '2013-02-12T12:37:47Z', '', '', '-1']\n",
      "The following line has imcomplete info and therefore it's been removed from the dataset:\n",
      "['5501150', '|Category:Nintendo Switch|', '14', '42046851', '2016-11-04T17:46:28Z', '', '', '-1']\n",
      "The following line has imcomplete info and therefore it's been removed from the dataset:\n",
      "['5501151', '|Category:Nintendo Switch遊戲|', '14', '42046854', '2016-11-04T17:47:30Z', '', '', '-1']\n",
      "The following line has imcomplete info and therefore it's been removed from the dataset:\n",
      "['5501189', '|Template:新力黨|', '10', '42047410', '2016-11-04T20:41:32Z', '', '', '-1']\n",
      "Done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.xml_to_csv('datasource/zhwiki-20190401-pages-articles.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liling/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasource/zhwiki-20190401-pages-articles.csv', quotechar='|', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>page_ns</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>contributor_name</th>\n",
       "      <th>bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wikipedia:Upload log</td>\n",
       "      <td>4</td>\n",
       "      <td>50308907</td>\n",
       "      <td>2018-07-08T05:56:22Z</td>\n",
       "      <td>2535439</td>\n",
       "      <td>Lopullinen</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Wikipedia:删除纪录/档案馆/2004年3月</td>\n",
       "      <td>4</td>\n",
       "      <td>1891425</td>\n",
       "      <td>2006-05-05T15:42:55Z</td>\n",
       "      <td>36</td>\n",
       "      <td>Lorenzarius</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>数学</td>\n",
       "      <td>0</td>\n",
       "      <td>52805680</td>\n",
       "      <td>2019-01-15T23:58:05Z</td>\n",
       "      <td>193.119.94.177</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>Help:目录</td>\n",
       "      <td>12</td>\n",
       "      <td>52484471</td>\n",
       "      <td>2018-12-22T18:41:57Z</td>\n",
       "      <td>1135158</td>\n",
       "      <td>Great Brightstar</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>哲学</td>\n",
       "      <td>0</td>\n",
       "      <td>53185911</td>\n",
       "      <td>2019-02-14T06:00:22Z</td>\n",
       "      <td>2688007</td>\n",
       "      <td>Archekamioto</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id                  page_title  page_ns  revision_id  \\\n",
       "0        1        Wikipedia:Upload log        4     50308907   \n",
       "1        2  Wikipedia:删除纪录/档案馆/2004年3月        4      1891425   \n",
       "2       13                          数学        0     52805680   \n",
       "3       14                     Help:目录       12     52484471   \n",
       "4       18                          哲学        0     53185911   \n",
       "\n",
       "              timestamp  contributor_id  contributor_name  bytes  \n",
       "0  2018-07-08T05:56:22Z         2535439        Lopullinen     -1  \n",
       "1  2006-05-05T15:42:55Z              36       Lorenzarius     -1  \n",
       "2  2019-01-15T23:58:05Z  193.119.94.177         Anonymous     -1  \n",
       "3  2018-12-22T18:41:57Z         1135158  Great Brightstar     -1  \n",
       "4  2019-02-14T06:00:22Z         2688007      Archekamioto     -1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_title_list = df['page_title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3274195"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_title_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 去除特殊字符**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return ''.join(re.findall('[\\w|\\d]+', string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wikipedia删除纪录档案馆2004年3月'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token('Wikipedia:删除纪录/档案馆/2004年3月')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_title_list = [token(str(page_title)) for page_title in page_title_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = ''.join(page_title for page_title in page_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48186959"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 切词，统计词频**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jh/b14_bh2n1753x9hvqr8zhtg40000gn/T/jieba.cache\n",
      "Loading model cost 0.825 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Wikipedia', '删除', '纪录', '档案馆', '2004', '年', '3', '月']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut('Wikipedia删除纪录档案馆2004年3月')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TOKENS = cut(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_list = ['Category', 'Template', 'Wikipedia', 'Help']\n",
    "valid_tokens = [t for t in ALL_TOKENS if t not in invalid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('年', 107673),\n",
       " ('的', 48046),\n",
       " ('月', 35982),\n",
       " ('条目', 29124),\n",
       " ('列表', 27524),\n",
       " ('站', 23638),\n",
       " ('日', 19435),\n",
       " ('小行星', 17783),\n",
       " ('街道', 15512),\n",
       " ('足球', 14453)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words_count = Counter(valid_tokens)\n",
    "words_count.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequences_all = [f for w, f  in words_count.most_common()]\n",
    "frequences_sum = sum(frequences_all)\n",
    "\n",
    "def get_prob(word):\n",
    "    esp = 1 / frequences_sum\n",
    "    if word in words_count:\n",
    "        return words_count[word] / frequences_sum\n",
    "    return esp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) 2-Gram Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2_grams_words = [''.join(valid_tokens[i:i+2]) for i in range(len(valid_tokens[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2_gram_sum = len(all_2_grams_words)\n",
    "all_2_gram_counter = Counter(all_2_grams_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_prob(w1, w2):\n",
    "    if w1 + w2 in all_2_gram_counter:\n",
    "        return all_2_gram_counter[w1+w2] / all_2_gram_sum\n",
    "    else:\n",
    "        return 1 / all_2_gram_sum\n",
    "    \n",
    "\n",
    "def get_prob_2_gram(previous, word):\n",
    "    return get_combination_prob(previous, word) / get_prob(previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def language_model_2_gram(string):\n",
    "    token_list = cut(string)\n",
    "    probability = 1\n",
    "    \n",
    "    for i, word in enumerate(token_list):\n",
    "        if i == 0:\n",
    "            probability = get_prob(word)\n",
    "        else:\n",
    "            probability = probability * get_prob_2_gram(token_list[i-1], word)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5642002718747821e-13"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('新一轮流感病毒正在东京蔓延')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6518967849097008e-09"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('中华人民共和国成立了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.963599284973264e-13"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('中国的图灵奖获得者')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0258369573431165e-10"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram('东汉末年分三国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.993959840010013e-14"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram(\"小明今天抽奖抽到一台波音飞机\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2527642350787167e-13"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model_2_gram(\"小明今天抽奖抽到一台苹果手机\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4 Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国文物在日本入侵时遭到毁坏 is more possible\n",
      "----中国文物在日本入侵时遭到毁坏 with probility 8.220765468899197e-20\n",
      "----中国文物在日本入侵时被收藏 with probility 1.332376899335364e-22\n",
      "维多利亚是一只漂亮的苏格兰折耳猫 is more possible\n",
      "----维多利亚是一只漂亮的苏格兰折耳猫 with probility 3.445966042514071e-19\n",
      "----维多利亚是一只漂亮的小野猫 with probility 1.731497409344307e-19\n",
      "诸葛亮是著名的军事家 is more possible\n",
      "----诸葛亮是著名的军事家 with probility 1.0300435127774173e-16\n",
      "----诸葛亮是王者荣耀里的角色 with probility 3.5798209726527275e-18\n",
      "养乐多绿来一杯 is more possible\n",
      "----洋葱奶昔来一杯 with probility 6.701031737483262e-10\n",
      "----养乐多绿来一杯 with probility 1.6618553185434128e-07\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"中国文物在日本入侵时遭到毁坏 中国文物在日本入侵时被收藏\",\n",
    "    \"维多利亚是一只漂亮的苏格兰折耳猫 维多利亚是一只漂亮的小野猫\",\n",
    "    \"诸葛亮是著名的军事家 诸葛亮是王者荣耀里的角色\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = language_model_2_gram(s1), language_model_2_gram(s2)\n",
    "    better =  s1 if p1 > p2 else s2\n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + '{} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + '{} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared to the previous learned parsing and pattern match problems. What's the advantage and disavantage of Probability Based Methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "**advantages:**  \n",
    "- 能够处理大量的数据；\n",
    "- 模型简单方便，易于理解；\n",
    "\n",
    "**disadvantages:**\n",
    "- 结果依赖于语料，通用性不强；\n",
    "- 实际情况中需要考虑周围多个词的条件概率，可能会使模型更加复杂；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional)  How to solve *OOV* problem?\n",
    "\n",
    "If some words are not in our dictionary or corpus. When we using language model, we need to overcome this `out-of-vocabulary`(OOV) problems. There are so many intelligent man to solve this probelm. \n",
    "\n",
    "-- \n",
    "\n",
    "The first question is: \n",
    "\n",
    "**Q1: How did you solve this problem in your programming task?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 词不存在时假设其只出现了一次；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the sencond question is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: Read about the 'Turing-Good Estimator', can explain the main points about this method, and may implement this method in your programming task**\n",
    "\n",
    "Reference: \n",
    "+ https://www.wikiwand.com/en/Good%E2%80%93Turing_frequency_estimation\n",
    "+ https://github.com/Computing-Intelligence/References/blob/master/NLP/Natural-Language-Processing.pdf, Page-37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TBD\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
